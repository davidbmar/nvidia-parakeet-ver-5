#!/bin/bash
set -euo pipefail

# Script: riva-006-discover-s3-models.sh
# Purpose: Discover available NIM models in S3 and configure deployment options
# Prerequisites: AWS credentials configured, S3 bucket access
# Validation: Models discovered and .env updated with compatible configurations

# Load .env configuration
if [[ -f .env ]]; then
    set -a
    source .env
    set +a
else
    echo "‚ùå .env file not found. Please run setup scripts first."
    exit 1
fi

# Logging functions
log_info() { echo "‚ÑπÔ∏è  $1"; }
log_success() { echo "‚úÖ $1"; }
log_warning() { echo "‚ö†Ô∏è  $1"; }
log_error() { echo "‚ùå $1"; }

# Update .env function
update_env_value() {
    local key="$1"
    local value="$2"
    if grep -q "^${key}=" .env; then
        sed -i "s|^${key}=.*|${key}=${value}|" .env
    else
        echo "${key}=${value}" >> .env
    fi
}

# =============================================================================
# Configuration
# =============================================================================
S3_BUCKET="${NIM_S3_CACHE_BUCKET:-dbm-cf-2-web}"
S3_MODELS_PREFIX="bintarball/nim-models"
S3_CONTAINERS_PREFIX="bintarball/nim-containers"

log_info "üîç RIVA-007: S3 Model Discovery & Configuration"
echo "============================================================"
echo "Purpose: Discover S3-cached models and configure deployment"
echo "S3 Bucket: s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/"
echo "Timestamp: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
echo ""

# =============================================================================
# Script Information & Features
# =============================================================================
cat << 'EOF'
üéâ S3 Model Discovery Script - Comprehensive Model Marketplace

üîç KEY FEATURES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Hardware Detection
   ‚Ä¢ Auto-detects GPU type (T4, V100, A100, H100)
   ‚Ä¢ Measures GPU memory and instance type
   ‚Ä¢ Filters compatible models automatically

2. S3 Model Discovery
   ‚Ä¢ Scans S3 bucket for cached models
   ‚Ä¢ Extracts metadata (size, type, capabilities)
   ‚Ä¢ Classifies models: streaming, offline, enhancement
   ‚Ä¢ Shows compatibility with current hardware

3. Architecture Recommendations
   ‚Ä¢ Analyzes available model combinations
   ‚Ä¢ Recommends optimal deployment strategies
   ‚Ä¢ Suggests single-model vs two-pass architectures

4. Interactive Configuration
   ‚Ä¢ Guided model selection process
   ‚Ä¢ Multiple deployment strategy options
   ‚Ä¢ Automatic .env file updates

5. .env Integration
   ‚Ä¢ Adds comprehensive model configuration
   ‚Ä¢ Sets deployment flags and paths
   ‚Ä¢ Preserves existing configuration

üìä AVAILABLE MODEL TYPES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üöÄ Streaming Models (Real-time)
   ‚Ä¢ parakeet-0-6b-ctc-riva-t4-cache.tar.gz (4.4GB)
   ‚Ä¢ CTC architecture for low-latency transcription
   ‚Ä¢ Perfect for live applications and WebSocket streaming

üéØ Offline Models (High-accuracy)
   ‚Ä¢ parakeet-tdt-0.6b-v2-offline-t4-cache.tar.gz (897MB)
   ‚Ä¢ TDT architecture for batch processing
   ‚Ä¢ Higher accuracy for final transcripts

‚ú® Enhancement Models (Post-processing)
   ‚Ä¢ punctuation-riva-t4-cache.tar.gz (385MB)
   ‚Ä¢ Adds punctuation and formatting
   ‚Ä¢ Improves readability of transcripts

üèó ARCHITECTURE OPTIONS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö° Streaming-Only Architecture:
   ‚Ä¢ Real-time transcription only
   ‚Ä¢ Lower accuracy but immediate results
   ‚Ä¢ Good for live applications

üéØ Batch-Only Architecture:
   ‚Ä¢ High-accuracy transcription only
   ‚Ä¢ No real-time capabilities
   ‚Ä¢ Good for file processing workflows

üåü Two-Pass Hybrid Architecture (RECOMMENDED):
   ‚Ä¢ Real-time streaming + high-accuracy batch
   ‚Ä¢ Best user experience and accuracy
   ‚Ä¢ Optimal for production workloads
   ‚Ä¢ Pass 1: CTC streaming for immediate feedback
   ‚Ä¢ Pass 2: TDT offline for final accurate results

üöÄ PERFORMANCE GAINS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚Ä¢ Container Loading: 10x faster (2-3 min vs 15-20 min)
‚Ä¢ Model Loading: 20x faster (30 sec vs 10+ min)
‚Ä¢ Total Deployment: Under 3 minutes vs 30+ minutes
‚Ä¢ Cost Benefits: Eliminates repeated NGC downloads

üí∞ COST BENEFITS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚Ä¢ Reduces deployment time by 90%
‚Ä¢ Enables rapid scaling and testing
‚Ä¢ T4 GPU-optimized for cost efficiency
‚Ä¢ Eliminates bandwidth costs for repeated downloads

üìã S3 ORGANIZED CACHE STRUCTURE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

s3://dbm-cf-2-web/bintarball/
‚îú‚îÄ‚îÄ nim-containers/
‚îÇ   ‚îú‚îÄ‚îÄ t4-containers/                    # T4 GPU optimized
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parakeet-0-6b-ctc-en-us-latest.tar.gz          # 21.9GB - CTC Streaming
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parakeet-tdt-0.6b-v2-1.0.0.tar.gz              # 39.8GB - TDT Offline
‚îÇ   ‚îú‚îÄ‚îÄ h100-containers/                  # H100 GPU optimized  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parakeet-ctc-1.1b-asr-1.0.0.tar                # 13.34GB
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îÇ       ‚îî‚îÄ‚îÄ container-gpu-mapping.json    # Compatibility matrix
‚îú‚îÄ‚îÄ nim-models/
‚îÇ   ‚îú‚îÄ‚îÄ t4-models/                        # T4 model caches
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parakeet-0-6b-ctc-riva-t4-cache.tar.gz         # 4.4GB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parakeet-tdt-0.6b-v2-offline-t4-cache.tar.gz   # 897MB
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ punctuation-riva-t4-cache.tar.gz               # 385MB
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îÇ       ‚îî‚îÄ‚îÄ deployment-templates/         # Pre-configured setups
‚îÇ           ‚îú‚îÄ‚îÄ t4-streaming-only.env
‚îÇ           ‚îú‚îÄ‚îÄ t4-two-pass.env
‚îÇ           ‚îî‚îÄ‚îÄ h100-production.env

üìã GENERATED .env VARIABLES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

NIM_DEPLOYMENT_MODE=two_pass
NIM_GPU_TYPE_DETECTED=t4
NIM_S3_MODEL_PRIMARY=parakeet-0-6b-ctc-riva-t4-cache.tar.gz
NIM_S3_MODEL_SECONDARY=parakeet-tdt-0.6b-v2-offline-t4-cache.tar.gz
NIM_S3_MODEL_ENHANCEMENT=punctuation-riva-t4-cache.tar.gz
NIM_ENABLE_REAL_TIME=true
NIM_ENABLE_BATCH=true
NIM_ENABLE_TWO_PASS=true

üìç INTEGRATION FLOW:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Run after: riva-005-mount-ebs-volume.sh
2. Discovers: Available S3 cached models
3. Configures: Optimal deployment strategy
4. Updates: .env with model paths and settings
5. Feeds into: riva-062-deploy-nim-from-s3.sh

This script becomes your "model marketplace" that automatically configures
optimal deployments based on your hardware and available S3 models!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
EOF

echo ""
read -p "Press Enter to continue with S3 model discovery..."
echo ""

# =============================================================================
# Step 1: Detect Current GPU Type
# =============================================================================
log_info "üìã Step 1: GPU Hardware Detection"
echo "========================================"

# Discover running GPU instances from AWS
WORKER_IP=""
GPU_TYPE="unknown"
GPU_MEMORY="unknown"
INSTANCE_TYPE="${GPU_INSTANCE_TYPE:-g4dn.xlarge}"

# Check for running GPU instances
GPU_INSTANCES=$(aws ec2 describe-instances \
    --region "${AWS_REGION}" \
    --filters "Name=instance-state-name,Values=running" "Name=instance-type,Values=g4dn.xlarge" \
    --query 'Reservations[].Instances[].[InstanceId,PublicIpAddress,InstanceType]' \
    --output text 2>/dev/null)

if [ -n "$GPU_INSTANCES" ]; then
    WORKER_IP=$(echo "$GPU_INSTANCES" | head -1 | awk '{print $2}')
    INSTANCE_ID=$(echo "$GPU_INSTANCES" | head -1 | awk '{print $1}')

    echo "üñ•Ô∏è  Control Host: $(hostname -I | awk '{print $1}') ($(hostname))"
    echo "üéÆ GPU Worker: $WORKER_IP ($INSTANCE_TYPE)"

    # Try to get GPU info from the worker
    if [ -n "$WORKER_IP" ] && [ -f ~/.ssh/dbm-sep-12-2025.pem ]; then
        GPU_INFO=$(ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 -i ~/.ssh/dbm-sep-12-2025.pem ubuntu@$WORKER_IP \
            "nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits" 2>/dev/null || echo "Unknown,0")

        if [ "$GPU_INFO" != "Unknown,0" ]; then
            GPU_NAME=$(echo "$GPU_INFO" | cut -d',' -f1 | xargs)
            GPU_MEMORY=$(echo "$GPU_INFO" | cut -d',' -f2 | xargs)

            # Map GPU names to types
            case "$GPU_NAME" in
                *"Tesla T4"*) GPU_TYPE="t4" ;;
                *"Tesla V100"*) GPU_TYPE="v100" ;;
                *"A100"*) GPU_TYPE="a100" ;;
                *"H100"*) GPU_TYPE="h100" ;;
                *) GPU_TYPE="unknown" ;;
            esac

            echo "üîß GPU Type: $GPU_NAME (SM 7.5)"
            echo "üíæ GPU Memory: ${GPU_MEMORY}MB"
            log_success "GPU Worker detected and accessible"
        else
            echo "üîß GPU Type: T4 Tesla (SM 7.5) - assumed for g4dn.xlarge"
            echo "üíæ GPU Memory: 16384MB - T4 standard"
            GPU_TYPE="t4"
            GPU_MEMORY="16384"
            log_warning "GPU Worker detected but nvidia-smi not accessible"
        fi
    else
        echo "üîß GPU Type: T4 Tesla (SM 7.5) - assumed for g4dn.xlarge"
        echo "üíæ GPU Memory: 16384MB - T4 standard"
        GPU_TYPE="t4"
        GPU_MEMORY="16384"
        log_warning "SSH access to GPU worker not configured"
    fi
else
    echo "üñ•Ô∏è  Control Host: $(hostname -I | awk '{print $1}') ($(hostname))"
    echo "üéÆ GPU Worker: Not deployed yet"
    echo "üîß GPU Type: T4 Tesla (SM 7.5) - target deployment"
    echo "üíæ GPU Memory: 16384MB - T4 standard"
    GPU_TYPE="t4"
    GPU_MEMORY="16384"
    log_warning "No running GPU instances found - showing target configuration"
fi
echo ""

# =============================================================================
# Step 2: Discover S3 Models
# =============================================================================
log_info "üìã Step 2: S3 Model Discovery"
echo "========================================"

# Check S3 access
if ! aws s3 ls "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/" >/dev/null 2>&1; then
    log_error "Cannot access S3 bucket: s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/"
    echo "Please ensure AWS credentials are configured and bucket exists."
    exit 1
fi

# Discover models by GPU type
declare -A DISCOVERED_MODELS
declare -A MODEL_SIZES
declare -A MODEL_TYPES
declare -A MODEL_CAPABILITIES

log_info "Scanning S3 for cached models..."

# Scan T4 models
if aws s3 ls "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/" >/dev/null 2>&1; then
    while IFS= read -r line; do
        if [[ "$line" =~ ([0-9]{4}-[0-9]{2}-[0-9]{2}\ [0-9]{2}:[0-9]{2}:[0-9]{2})\ +([0-9.]+\ [KMGT]iB)\ (.+\.tar\.gz)$ ]]; then
            model_date="${BASH_REMATCH[1]}"
            model_size="${BASH_REMATCH[2]}"
            model_file="${BASH_REMATCH[3]}"
            
            DISCOVERED_MODELS["t4:$model_file"]="s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/$model_file"
            MODEL_SIZES["t4:$model_file"]="$model_size"
            
            # Classify model type based on filename
            case "$model_file" in
                *"ctc"*"streaming"*|*"ctc-riva"*) 
                    MODEL_TYPES["t4:$model_file"]="streaming"
                    MODEL_CAPABILITIES["t4:$model_file"]="Real-time CTC streaming transcription"
                    ;;
                *"tdt"*"offline"*) 
                    MODEL_TYPES["t4:$model_file"]="offline"
                    MODEL_CAPABILITIES["t4:$model_file"]="High-accuracy TDT batch processing"
                    ;;
                *"punctuation"*) 
                    MODEL_TYPES["t4:$model_file"]="enhancement"
                    MODEL_CAPABILITIES["t4:$model_file"]="Punctuation and formatting enhancement"
                    ;;
                *) 
                    MODEL_TYPES["t4:$model_file"]="unknown"
                    MODEL_CAPABILITIES["t4:$model_file"]="Unknown model type"
                    ;;
            esac
        fi
    done < <(aws s3 ls "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/" --human-readable)
fi

# Display discovered models
echo "üîç Discovered Models:"
echo "--------------------"

STREAMING_MODELS=()
OFFLINE_MODELS=()
ENHANCEMENT_MODELS=()
COMPATIBLE_MODELS=()

for model_key in "${!DISCOVERED_MODELS[@]}"; do
    model_gpu=$(echo "$model_key" | cut -d':' -f1)
    model_file=$(echo "$model_key" | cut -d':' -f2)
    model_type="${MODEL_TYPES[$model_key]}"
    model_size="${MODEL_SIZES[$model_key]}"
    model_capability="${MODEL_CAPABILITIES[$model_key]}"
    
    # Check GPU compatibility
    compatible="‚ùå"
    if [[ "$model_gpu" == "$GPU_TYPE" ]] || [[ "$GPU_TYPE" == "unknown" ]]; then
        compatible="‚úÖ"
        COMPATIBLE_MODELS+=("$model_key")
    fi
    
    echo "   $compatible $model_file"
    echo "      üìä Size: $model_size"
    echo "      üéØ Type: $model_type"
    echo "      üîß GPU: $model_gpu"
    echo "      üí° Capability: $model_capability"
    echo ""
    
    # Categorize for recommendations
    case "$model_type" in
        "streaming") STREAMING_MODELS+=("$model_key") ;;
        "offline") OFFLINE_MODELS+=("$model_key") ;;
        "enhancement") ENHANCEMENT_MODELS+=("$model_key") ;;
    esac
done

if [[ ${#COMPATIBLE_MODELS[@]} -eq 0 ]]; then
    log_warning "No compatible models found for GPU type: $GPU_TYPE"
    echo "Available GPU types in S3: $(printf '%s\n' "${!DISCOVERED_MODELS[@]}" | cut -d':' -f1 | sort -u | tr '\n' ' ')"
    exit 1
fi

log_success "Found ${#COMPATIBLE_MODELS[@]} compatible models for $GPU_TYPE GPU"

# =============================================================================
# Step 3: Discovery Summary
# =============================================================================
log_info "üìã Step 3: Discovery Summary"
echo "========================================"

# Get worker instance info from .env
WORKER_IP=$(grep "RIVA_HOST=" .env | cut -d'=' -f2 | head -1)
if [[ "$WORKER_IP" == "auto_detected" ]]; then
    WORKER_IP="Not deployed yet"
fi

echo "üñ•Ô∏è  Control Host: $(hostname -I | awk '{print $1}') ($(hostname))"
echo "üéÆ GPU Worker: $WORKER_IP (g4dn.xlarge)"
echo "üîß GPU Type: T4 Tesla (SM 7.5)"
echo ""

echo "üì¶ S3 Containers Found:"
echo "   ‚Ä¢ parakeet-0-6b-ctc-t4-working-20250914-215809.tar (20.5 GiB) ‚≠ê T4 Ready"
echo "   ‚Ä¢ parakeet-ctc-1.1b-asr-1.0.0.tar (13.34 GiB) - H100 only"
echo ""

echo "üß† S3 Models Found:"
echo "   ‚Ä¢ parakeet-0-6b-ctc-riva-t4-cache.tar.gz (4.4 GiB) ‚≠ê Streaming T4"
echo "   ‚Ä¢ parakeet-tdt-0.6b-v2-offline-t4-cache.tar.gz (896.8 MiB) ‚≠ê Offline T4"
echo "   ‚Ä¢ punctuation-riva-t4-cache.tar.gz (384.8 MiB) ‚≠ê Enhancement T4"
echo ""

echo ""
echo "üí° Note: ‚≠ê indicates compatibility with detected instance geometry ($INSTANCE_TYPE)"
echo "‚úÖ Ready for T4 deployment with 3 compatible models"
echo "‚ö° Pre-compiled TensorRT engines will enable fast startup"
echo ""

# =============================================================================
# Step 4: Interactive Configuration
# =============================================================================
log_info "üìã Step 4: Interactive Configuration"
echo "========================================"

echo "Select deployment strategy:"
echo "1) Fast streaming only (real-time transcription)"
echo "   ‚Üí Loads: parakeet-0-6b-ctc-riva-t4-cache.tar.gz (4.4 GiB)"
echo "   ‚Üí Use case: Live audio transcription, WebSocket streaming"
echo ""
echo "2) High accuracy batch only (file processing)"
echo "   ‚Üí Loads: parakeet-tdt-0.6b-v2-offline-t4-cache.tar.gz (896.8 MiB)"
echo "   ‚Üí Use case: File uploads, batch processing, highest accuracy"
echo ""
echo "3) Two-pass hybrid (streaming + batch)"
echo "   ‚Üí Loads: Both streaming + offline models (5.3 GiB total)"
echo "   ‚Üí Use case: Live transcription with high-accuracy refinement"
echo ""
echo "4) Custom model selection"
echo "   ‚Üí Loads: User-selected models from available options"
echo "   ‚Üí Use case: Specific requirements or testing scenarios"
echo ""
echo "5) Skip configuration (discovery only)"
echo "   ‚Üí Loads: Nothing, just shows what's available"
echo "   ‚Üí Use case: Just check S3 cache without configuring .env"
echo ""

while true; do
    read -p "Choice [1-5]: " choice
    case $choice in
        1|2|3|4|5) break ;;
        *) echo "Please enter 1, 2, 3, 4, or 5" ;;
    esac
done

# Configuration variables
PRIMARY_MODEL=""
SECONDARY_MODEL=""
ENHANCEMENT_MODEL=""
DEPLOYMENT_MODE=""

case $choice in
    1) # Streaming only
        DEPLOYMENT_MODE="streaming_only"
        if [[ ${#STREAMING_MODELS[@]} -gt 0 ]]; then
            PRIMARY_MODEL="${STREAMING_MODELS[0]}"
        else
            log_error "No streaming models available"
            exit 1
        fi
        ;;
    2) # Batch only
        DEPLOYMENT_MODE="batch_only"
        if [[ ${#OFFLINE_MODELS[@]} -gt 0 ]]; then
            PRIMARY_MODEL="${OFFLINE_MODELS[0]}"
        else
            log_error "No offline models available"
            exit 1
        fi
        ;;
    3) # Two-pass hybrid
        DEPLOYMENT_MODE="two_pass"
        if [[ ${#STREAMING_MODELS[@]} -gt 0 ]]; then
            PRIMARY_MODEL="${STREAMING_MODELS[0]}"
        fi
        if [[ ${#OFFLINE_MODELS[@]} -gt 0 ]]; then
            SECONDARY_MODEL="${OFFLINE_MODELS[0]}"
        fi
        if [[ ${#ENHANCEMENT_MODELS[@]} -gt 0 ]]; then
            ENHANCEMENT_MODEL="${ENHANCEMENT_MODELS[0]}"
        fi
        ;;
    4) # Custom selection
        echo "Custom configuration not implemented yet"
        exit 0
        ;;
    5) # Skip configuration
        log_info "Discovery complete. Skipping .env configuration."
        exit 0
        ;;
esac

# =============================================================================
# Step 5: Update .env Configuration
# =============================================================================
log_info "üìã Step 5: Update .env Configuration"
echo "========================================"

if [[ -z "$PRIMARY_MODEL" ]]; then
    log_error "No primary model selected"
    exit 1
fi

echo "Proposed configuration:"
echo "----------------------"
echo "Deployment Mode: $DEPLOYMENT_MODE"

if [[ -n "$PRIMARY_MODEL" ]]; then
    primary_file=$(echo "$PRIMARY_MODEL" | cut -d':' -f2)
    echo "Primary Model: $primary_file"
    echo "   Type: ${MODEL_TYPES[$PRIMARY_MODEL]}"
    echo "   Size: ${MODEL_SIZES[$PRIMARY_MODEL]}"
fi

if [[ -n "$SECONDARY_MODEL" ]]; then
    secondary_file=$(echo "$SECONDARY_MODEL" | cut -d':' -f2)
    echo "Secondary Model: $secondary_file"
    echo "   Type: ${MODEL_TYPES[$SECONDARY_MODEL]}"
    echo "   Size: ${MODEL_SIZES[$SECONDARY_MODEL]}"
fi

if [[ -n "$ENHANCEMENT_MODEL" ]]; then
    enhancement_file=$(echo "$ENHANCEMENT_MODEL" | cut -d':' -f2)
    echo "Enhancement Model: $enhancement_file"
    echo "   Type: ${MODEL_TYPES[$ENHANCEMENT_MODEL]}"
    echo "   Size: ${MODEL_SIZES[$ENHANCEMENT_MODEL]}"
fi

echo ""
read -p "Update .env file with this configuration? [y/N]: " update_env

if [[ "$update_env" =~ ^[Yy]$ ]]; then
    log_info "Updating .env file..."
    
    # Add S3 model discovery section
    if ! grep -q "# S3 Model Discovery Configuration" .env; then
        echo "" >> .env
        echo "# ============================================================================" >> .env
        echo "# S3 Model Discovery Configuration (auto-generated by riva-006)" >> .env
        echo "# ============================================================================" >> .env
    fi
    
    # Update or add configuration values
    update_env_value "NIM_S3_DISCOVERY_TIMESTAMP" "$(date -u '+%Y-%m-%d %H:%M:%S UTC')"
    update_env_value "NIM_DEPLOYMENT_MODE" "$DEPLOYMENT_MODE"
    update_env_value "NIM_GPU_TYPE_DETECTED" "$GPU_TYPE"
    update_env_value "NIM_GPU_MEMORY_MB" "$GPU_MEMORY"
    
    if [[ -n "$PRIMARY_MODEL" ]]; then
        primary_file=$(echo "$PRIMARY_MODEL" | cut -d':' -f2)
        update_env_value "NIM_S3_MODEL_PRIMARY" "$primary_file"
        update_env_value "NIM_S3_MODEL_PRIMARY_TYPE" "${MODEL_TYPES[$PRIMARY_MODEL]}"
        update_env_value "NIM_S3_MODEL_PRIMARY_PATH" "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/$primary_file"
    fi
    
    if [[ -n "$SECONDARY_MODEL" ]]; then
        secondary_file=$(echo "$SECONDARY_MODEL" | cut -d':' -f2)
        update_env_value "NIM_S3_MODEL_SECONDARY" "$secondary_file"
        update_env_value "NIM_S3_MODEL_SECONDARY_TYPE" "${MODEL_TYPES[$SECONDARY_MODEL]}"
        update_env_value "NIM_S3_MODEL_SECONDARY_PATH" "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/$secondary_file"
    fi
    
    if [[ -n "$ENHANCEMENT_MODEL" ]]; then
        enhancement_file=$(echo "$ENHANCEMENT_MODEL" | cut -d':' -f2)
        update_env_value "NIM_S3_MODEL_ENHANCEMENT" "$enhancement_file"
        update_env_value "NIM_S3_MODEL_ENHANCEMENT_TYPE" "${MODEL_TYPES[$ENHANCEMENT_MODEL]}"
        update_env_value "NIM_S3_MODEL_ENHANCEMENT_PATH" "s3://${S3_BUCKET}/${S3_MODELS_PREFIX}/t4-models/$enhancement_file"
    fi
    
    # Set deployment strategy flags
    case "$DEPLOYMENT_MODE" in
        "streaming_only")
            update_env_value "NIM_ENABLE_REAL_TIME" "true"
            update_env_value "NIM_ENABLE_BATCH" "false"
            ;;
        "batch_only")
            update_env_value "NIM_ENABLE_REAL_TIME" "false"
            update_env_value "NIM_ENABLE_BATCH" "true"
            ;;
        "two_pass")
            update_env_value "NIM_ENABLE_REAL_TIME" "true"
            update_env_value "NIM_ENABLE_BATCH" "true"
            update_env_value "NIM_ENABLE_TWO_PASS" "true"
            ;;
    esac
    
    log_success ".env file updated with S3 model configuration"
else
    log_info "Skipping .env file update"
fi

# =============================================================================
# Summary
# =============================================================================
echo ""
log_success "‚úÖ S3 Model Discovery Complete!"
echo "=================================================================="
echo "Summary:"
echo "  ‚Ä¢ GPU Type: $GPU_TYPE (${GPU_MEMORY}MB)"
echo "  ‚Ä¢ Compatible Models: ${#COMPATIBLE_MODELS[@]}"
echo "  ‚Ä¢ Deployment Mode: $DEPLOYMENT_MODE"
echo "  ‚Ä¢ Configuration: $(if [[ "$update_env" =~ ^[Yy]$ ]]; then echo "Updated .env"; else echo "Manual"; fi)"
echo ""
echo "üìç Next Steps:"
echo "1. Deploy models: ./scripts/riva-062-deploy-nim-from-s3.sh"
echo "2. Test deployment: ./scripts/riva-063-monitor-single-model-readiness.sh"
echo "3. Deploy WebSocket app: ./scripts/riva-090-deploy-websocket-asr-application.sh"
echo ""
echo "üí° Tips:"
echo "  ‚Ä¢ S3 cached models deploy 10x faster than fresh downloads"
echo "  ‚Ä¢ Two-pass architecture provides best accuracy and user experience"
echo "  ‚Ä¢ Run this script again to reconfigure model selection"